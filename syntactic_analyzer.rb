require_relative 'lexical_analyzer'
require_relative 'token'

class SyntacticAnalyzer

  NON_TERMINALS = [:dtddocument, :dtddocument2, :declaration, :elemdecl, :elemdecl2, :elemchild, :choiceseq, :choiceseq2,
    :choiceseq3, :choice, :cp, :cp2, :x, :attrdecl, :attrdecl2, :attrdecl3, :attrdecl4, :attrtype, :attrtype2, :defaultdecl,
    :defaultdecl2, :defaultdecl3, :name, :name2, :name3, :namechar, :letter, :number, :number2, :digit, :word, :word2, :char]

  RULES = {
      '1': [:dtddocument2, :declaration],
      '2': [:dtddocument],
      '3': [],
      '4': [:attrdecl],
      '5': [:elemdecl],
      '6': [Token.new(:regular, '>'), :elemdecl2, :name, Token.new(:tag, '<!ELEMENT')],
      '7': [Token.new(:tag, 'EMPTY')],
      '8': [Token.new(:tag, 'ANY')],
      '9': [Token.new(:tag, '(#PCDATA)')],
      '10': [:elemchild],
      '11': [Token.new(:regular, ')'), :x, Token.new(:regular, '(')],
      '12': [:choiceseq3, :cp, Token.new(:regular, '(')],
      '13': [:choice],
      '14': [:choiceseq2, :cp, Token.new(:regular, ',')],
      '15': [],
      '16': [Token.new(:regular, ')'), :choiceseq2],
      '17': [:cp, Token.new(:regular, '|')],
      '18': [:cp2, :name],
      '19': [:x],
      '20': [],
      '21': [Token.new(:regular, '?')],
      '22': [Token.new(:regular, '*')],
      '23': [Token.new(:regular, '+')],
      '24': [:cp2, :choiceseq],
      '25': [:attrdecl3, :name, Token.new(:tag, '<!ATTLIST')],
      '26': [:attrdecl4, :defaultdecl, :attrtype, :name],
      '27': [Token.new(:regular, '>')],
      '28': [Token.new(:regular, '>'), :attrdecl2, Token.new(:tag, 'SPACE')],
      '29': [],
      '30': [:attrdecl2],
      '31': [Token.new(:tag, 'CDATA')],
      '32': [Token.new(:tag, 'NMTOKEN')],
      '33': [Token.new(:tag, 'IDREF')],
      '34': [:attrtype2, :word, Token.new(:regular, '(')],
      '35': [Token.new(:regular, ')')],
      '36': [Token.new(:regular, ')'), :word, Token.new(:regular, '|')],
      '37': [Token.new(:tag, '#REQUIRED')],
      '38': [Token.new(:tag, '#IMPLIED')],
      '39': [Token.new(:regular, '"'), :defaultdecl2, Token.new(:regular, '"')],
      '40': [Token.new(:regular, '"'), :defaultdecl2, Token.new(:regular, '"'), Token.new(:tag, '#FIXED')],
      '41': [:defaultdecl3, :word],
      '42': [],
      '43': [:defaultdecl2, Token.new(:tag, 'SPACE')],
      '44': [:name3, :letter],
      '45': [:name3, Token.new(:regular, '_')],
      '46': [:name3, Token.new(:regular, ':')],
      '47': [:name3, :namechar],
      '48': [],
      '49': [:name2],
      '50': [:letter],
      '51': [:digit],
      '52': [Token.new(:regular, '.')],
      '53': [Token.new(:regular, '-')],
      '54': [Token.new(:regular, '_')],
      '55': [Token.new(:regular, ':')],
      '56': [Token.new(:regular, 'A')],
      '57': [Token.new(:regular, 'B')],
      '58': [Token.new(:regular, 'C')],
      '59': [Token.new(:regular, 'D')],
      '60': [Token.new(:regular, 'E')],
      '61': [Token.new(:regular, 'F')],
      '62': [Token.new(:regular, 'G')],
      '63': [Token.new(:regular, 'H')],
      '64': [Token.new(:regular, 'I')],
      '65': [Token.new(:regular, 'J')],
      '66': [Token.new(:regular, 'K')],
      '67': [Token.new(:regular, 'L')],
      '68': [Token.new(:regular, 'M')],
      '69': [Token.new(:regular, 'N')],
      '70': [Token.new(:regular, 'O')],
      '71': [Token.new(:regular, 'P')],
      '72': [Token.new(:regular, 'Q')],
      '73': [Token.new(:regular, 'R')],
      '74': [Token.new(:regular, 'S')],
      '75': [Token.new(:regular, 'T')],
      '76': [Token.new(:regular, 'U')],
      '77': [Token.new(:regular, 'V')],
      '78': [Token.new(:regular, 'W')],
      '79': [Token.new(:regular, 'X')],
      '80': [Token.new(:regular, 'Y')],
      '81': [Token.new(:regular, 'Z')],
      '82': [Token.new(:regular, 'a')],
      '83': [Token.new(:regular, 'b')],
      '84': [Token.new(:regular, 'c')],
      '85': [Token.new(:regular, 'd')],
      '86': [Token.new(:regular, 'e')],
      '87': [Token.new(:regular, 'f')],
      '88': [Token.new(:regular, 'g')],
      '89': [Token.new(:regular, 'h')],
      '90': [Token.new(:regular, 'i')],
      '91': [Token.new(:regular, 'j')],
      '92': [Token.new(:regular, 'k')],
      '93': [Token.new(:regular, 'l')],
      '94': [Token.new(:regular, 'm')],
      '95': [Token.new(:regular, 'n')],
      '96': [Token.new(:regular, 'o')],
      '97': [Token.new(:regular, 'p')],
      '98': [Token.new(:regular, 'q')],
      '99': [Token.new(:regular, 'r')],
      '100': [Token.new(:regular, 's')],
      '101': [Token.new(:regular, 't')],
      '102': [Token.new(:regular, 'u')],
      '103': [Token.new(:regular, 'v')],
      '104': [Token.new(:regular, 'w')],
      '105': [Token.new(:regular, 'x')],
      '106': [Token.new(:regular, 'y')],
      '107': [Token.new(:regular, 'z')],
      '108': [:number2, :digit],
      '109': [],
      '110': [:number],
      '111': [Token.new(:regular, '0')],
      '112': [Token.new(:regular, '1')],
      '113': [Token.new(:regular, '2')],
      '114': [Token.new(:regular, '3')],
      '115': [Token.new(:regular, '4')],
      '116': [Token.new(:regular, '5')],
      '117': [Token.new(:regular, '6')],
      '118': [Token.new(:regular, '7')],
      '119': [Token.new(:regular, '8')],
      '120': [Token.new(:regular, '9')],
      '121': [:word2, :char],
      '122': [],
      '123': [:word],
      '124': [:letter],
      '125': [:digit],
      '126': [Token.new(:regular, '!')],
      '127': [Token.new(:regular, '?')],
      '128': [Token.new(:regular, ';')],
      '129': [Token.new(:regular, '@')],
      '130': [Token.new(:regular, '&')],
      '131': [Token.new(:regular, '+')],
      '132': [Token.new(:regular, '*')],
  }

  STT = {
      :dtddocument => {
          '<!ATTRLIST': '1',
          '<!ELEMENT': '1'
      },
      :dtddocument2 => {
          '<!ATTRLIST': '2',
          '<!ELEMENT': '2',
          '$': '3'
      }
  }

  def self.analyze
    tokens = LexicalAnalyzer.get_tokens

    tokens.each do |token|
      puts token.inspect
    end

  end
end

LexicalAnalyzer.load_input
SyntacticAnalyzer.analyze